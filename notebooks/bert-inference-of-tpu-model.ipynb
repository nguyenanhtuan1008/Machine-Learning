{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT on Steroids: Fine-tuning BERT for a dataset using PyTorch and Google Cloud TPUs\n",
    "\n",
    "https://www.youtube.com/watch?v=B_P0ZIXspOU\n",
    "\n",
    "https://www.kaggle.com/abhishek/bert-inference-of-tpu-model/\n",
    "\n",
    "If you like this kernel, consider upvoting it and the associated datasets:\n",
    "- https://www.kaggle.com/abhishek/bert-base-uncased\n",
    "- https://www.kaggle.com/abhishek/tpubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self, bert_path):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert_path = bert_path\n",
    "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, 30)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            ids,\n",
    "            mask,\n",
    "            token_type_ids\n",
    "    ):\n",
    "        _, o2 = self.bert(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids)\n",
    "\n",
    "        bo = self.bert_drop(o2)\n",
    "        p2 = self.out(bo)\n",
    "        return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDatasetTest:\n",
    "    def __init__(self, qtitle, qbody, answer, tokenizer, max_length):\n",
    "        self.qtitle = qtitle\n",
    "        self.qbody = qbody\n",
    "        self.answer = answer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answer)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        question_title = str(self.qtitle[item])\n",
    "        question_body = str(self.qbody[item])\n",
    "        answer_text = str(self.answer[item])\n",
    "\n",
    "        question_title = \" \".join(question_title.split())\n",
    "        question_body = \" \".join(question_body.split())\n",
    "        answer_text = \" \".join(answer_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question_title + \" \" + question_body,\n",
    "            answer_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = self.max_length - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    TEST_BATCH_SIZE = 8\n",
    "    TEST_DATASET = \"../input/google-quest-challenge/test.csv\"\n",
    "    df = pd.read_csv(TEST_DATASET).fillna(\"none\")\n",
    "\n",
    "    qtitle = df.question_title.values.astype(str).tolist()\n",
    "    qbody = df.question_body.values.astype(str).tolist()\n",
    "    answer = df.answer.values.astype(str).tolist()\n",
    "    category = df.category.values.astype(str).tolist()\n",
    "\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased/\", \n",
    "                                                           do_lower_case=True)\n",
    "    maxlen = 512\n",
    "    predictions = []\n",
    "\n",
    "    test_dataset = BERTDatasetTest(\n",
    "        qtitle=qtitle,\n",
    "        qbody=qbody,\n",
    "        answer=answer,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=TEST_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    model = BERTBaseUncased(\"../input/bert-base-uncased/\")\n",
    "    model.to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"../input/tpubert/model.bin\"))\n",
    "    model.eval()\n",
    "\n",
    "    tk0 = tqdm(test_data_loader, total=int(len(test_dataset) / test_data_loader.batch_size))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "\n",
    "        ids = ids.to(DEVICE, dtype=torch.long)\n",
    "        mask = mask.to(DEVICE, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            outputs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    return np.vstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:11,  5.09it/s]                        \n"
     ]
    }
   ],
   "source": [
    "preds = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SUBMISSION = \"../input/google-quest-challenge/sample_submission.csv\"\n",
    "sample = pd.read_csv(SAMPLE_SUBMISSION)\n",
    "target_cols = list(sample.drop(\"qa_id\", axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[target_cols] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.923931</td>\n",
       "      <td>0.653783</td>\n",
       "      <td>0.152824</td>\n",
       "      <td>0.721629</td>\n",
       "      <td>0.573089</td>\n",
       "      <td>0.499188</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>0.632832</td>\n",
       "      <td>0.437973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899433</td>\n",
       "      <td>0.947756</td>\n",
       "      <td>0.722048</td>\n",
       "      <td>0.974332</td>\n",
       "      <td>0.986972</td>\n",
       "      <td>0.915564</td>\n",
       "      <td>0.128216</td>\n",
       "      <td>0.040347</td>\n",
       "      <td>0.863238</td>\n",
       "      <td>0.959550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.890830</td>\n",
       "      <td>0.599214</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.938664</td>\n",
       "      <td>0.489424</td>\n",
       "      <td>0.372735</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714050</td>\n",
       "      <td>0.945723</td>\n",
       "      <td>0.570837</td>\n",
       "      <td>0.960279</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.883028</td>\n",
       "      <td>0.953711</td>\n",
       "      <td>0.102567</td>\n",
       "      <td>0.102702</td>\n",
       "      <td>0.920847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.919508</td>\n",
       "      <td>0.681343</td>\n",
       "      <td>0.025285</td>\n",
       "      <td>0.820728</td>\n",
       "      <td>0.929896</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.623493</td>\n",
       "      <td>0.476292</td>\n",
       "      <td>0.248541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901854</td>\n",
       "      <td>0.950572</td>\n",
       "      <td>0.651936</td>\n",
       "      <td>0.976627</td>\n",
       "      <td>0.987081</td>\n",
       "      <td>0.917535</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.912564</td>\n",
       "      <td>0.945181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.888797</td>\n",
       "      <td>0.438063</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.697785</td>\n",
       "      <td>0.845357</td>\n",
       "      <td>0.951296</td>\n",
       "      <td>0.458818</td>\n",
       "      <td>0.365853</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669545</td>\n",
       "      <td>0.957263</td>\n",
       "      <td>0.711225</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>0.992892</td>\n",
       "      <td>0.914670</td>\n",
       "      <td>0.864915</td>\n",
       "      <td>0.095046</td>\n",
       "      <td>0.680777</td>\n",
       "      <td>0.925022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.927154</td>\n",
       "      <td>0.672999</td>\n",
       "      <td>0.050325</td>\n",
       "      <td>0.860924</td>\n",
       "      <td>0.788344</td>\n",
       "      <td>0.825572</td>\n",
       "      <td>0.594543</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.101299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843456</td>\n",
       "      <td>0.948001</td>\n",
       "      <td>0.650135</td>\n",
       "      <td>0.977154</td>\n",
       "      <td>0.988778</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.180683</td>\n",
       "      <td>0.019010</td>\n",
       "      <td>0.759257</td>\n",
       "      <td>0.959902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.923931                0.653783   \n",
       "1     46                             0.890830                0.599214   \n",
       "2     70                             0.919508                0.681343   \n",
       "3    132                             0.888797                0.438063   \n",
       "4    200                             0.927154                0.672999   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.152824                      0.721629   \n",
       "1                 0.005323                      0.786957   \n",
       "2                 0.025285                      0.820728   \n",
       "3                 0.005873                      0.697785   \n",
       "4                 0.050325                      0.860924   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.573089                               0.499188   \n",
       "1               0.901266                               0.938664   \n",
       "2               0.929896                               0.937346   \n",
       "3               0.845357                               0.951296   \n",
       "4               0.788344                               0.825572   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.661548                       0.632832   \n",
       "1                         0.489424                       0.372735   \n",
       "2                         0.623493                       0.476292   \n",
       "3                         0.458818                       0.365853   \n",
       "4                         0.594543                       0.552499   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.437973  ...               0.899433        0.947756   \n",
       "1               0.032964  ...               0.714050        0.945723   \n",
       "2               0.248541  ...               0.901854        0.950572   \n",
       "3               0.083867  ...               0.669545        0.957263   \n",
       "4               0.101299  ...               0.843456        0.948001   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.722048          0.974332          0.986972   \n",
       "1                     0.570837          0.960279          0.977561   \n",
       "2                     0.651936          0.976627          0.987081   \n",
       "3                     0.711225          0.985153          0.992892   \n",
       "4                     0.650135          0.977154          0.988778   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.915564                  0.128216               0.040347   \n",
       "1             0.883028                  0.953711               0.102567   \n",
       "2             0.917535                  0.076725               0.034214   \n",
       "3             0.914670                  0.864915               0.095046   \n",
       "4             0.927007                  0.180683               0.019010   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.863238             0.959550  \n",
       "1                        0.102702             0.920847  \n",
       "2                        0.912564             0.945181  \n",
       "3                        0.680777             0.925022  \n",
       "4                        0.759257             0.959902  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
